# app.py
import streamlit as st
from PIL import Image
import numpy as np
import os
from utils import load_model, load_data, normalize_features, get_pca_transform, encode_text, encode_image, compute_similarity, get_topk_images

# é…ç½®è·¯å¾„ï¼ˆè¯·æ ¹æ®å®é™…æƒ…å†µä¿®æ”¹ï¼‰
EMBEDDING_PATH = "image_embeddings.pickle"  # å·²æœ‰çš„ embeddings æ–‡ä»¶
IMAGE_FOLDER = "coco_images_resized"        # è§£å‹åçš„å›¾ç‰‡æ–‡ä»¶å¤¹

# å…¨å±€æ ·å¼
st.markdown(
    """
    <style>
    body {
        background-color: #f9f9f9;
        font-family: 'Arial', sans-serif;
    }
    h1 {
        color: #4CAF50;
        text-align: center;
        font-size: 3em;
    }
    .stButton button {
        background-color: #4CAF50;
        color: white;
        border-radius: 5px;
        font-size: 16px;
    }
    .stSlider {
        color: #4CAF50;
    }
    </style>
    """,
    unsafe_allow_html=True
)

# åº”ç”¨æ ‡é¢˜
st.markdown("<h1>CS506: Image Search Application</h1>", unsafe_allow_html=True)

# åŠ è½½ CLIP æ¨¡å‹å’Œæ•°æ®
@st.cache_resource
def initialize():
    model, preprocess_val = load_model()
    df, embeddings, file_names = load_data(EMBEDDING_PATH, IMAGE_FOLDER)
    embeddings = normalize_features(embeddings)

    # å‡†å¤‡ PCA ç‰¹å¾
    pca_k = 100
    pca, reduced_embeddings = get_pca_transform(embeddings, k=pca_k)
    reduced_embeddings = normalize_features(reduced_embeddings)
    return model, preprocess_val, df, embeddings, file_names, pca, reduced_embeddings

model, preprocess_val, df, embeddings, file_names, pca, reduced_embeddings = initialize()

# åˆ†ä¸ºä¸¤åˆ—å¸ƒå±€
col1, col2 = st.columns([1, 1])

with col1:
    # æ–‡æœ¬è¾“å…¥
    text_query = st.text_input("ğŸ” Enter a text query", "")

with col2:
    # å›¾åƒä¸Šä¼ 
    uploaded_file = st.file_uploader(
        "ğŸ“¤ Upload an image query",
        type=["jpg", "jpeg", "png"]
    )

# ä¸­é—´åˆ†éš”çº¿
st.markdown("<hr style='border:2px solid #4CAF50;'>", unsafe_allow_html=True)

# æ»‘å—å’Œé€‰æ‹©æ¡†
lambda_val = st.slider("âš–ï¸ Adjust text vs image weight (Î»)", 0.0, 1.0, 0.5, key="slider")
feature_type = st.selectbox("ğŸ› ï¸ Choose feature type", ["CLIP", "PCA"])

# æœç´¢æŒ‰é’®
if st.button("Search ğŸš€"):
    text_query_vec = None
    image_query_vec = None

    # æ–‡æœ¬æŸ¥è¯¢
    if text_query.strip():
        text_query_vec = encode_text(model, [text_query])

    # å›¾åƒæŸ¥è¯¢
    if uploaded_file:
        img = Image.open(uploaded_file).convert("RGB")
        image_query_vec = encode_image(model, preprocess_val, img)

    # åˆæˆæœ€ç»ˆæŸ¥è¯¢å‘é‡
    if text_query_vec is not None and image_query_vec is not None:
        combined = lambda_val * text_query_vec + (1 - lambda_val) * image_query_vec
        query_vector = combined / np.linalg.norm(combined, axis=1, keepdims=True)
    elif text_query_vec is not None:
        query_vector = text_query_vec
    elif image_query_vec is not None:
        query_vector = image_query_vec
    else:
        st.error("âš ï¸ Please provide at least one query (text or image).")
        st.stop()

    # æ ¹æ®ç‰¹å¾ç±»å‹å¤„ç†æŸ¥è¯¢
    if feature_type == "PCA":
        query_vector_pca = pca.transform(query_vector)
        query_vector_pca = query_vector_pca / np.linalg.norm(query_vector_pca, axis=1, keepdims=True)
        scores = compute_similarity(query_vector_pca, reduced_embeddings)
    else:
        scores = compute_similarity(query_vector, embeddings)

    # è·å–å¹¶æ˜¾ç¤ºå‰ k ä¸ªç»“æœ
    results = get_topk_images(scores, file_names, k=5)

    st.subheader("Search Results:")
    for fname, score in results:
        st.write(f"Image: {fname}, Score: {score:.4f}")
        img_path = os.path.join(IMAGE_FOLDER, fname)
        st.image(img_path, width=200)
